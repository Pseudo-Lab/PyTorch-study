{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7rGWzMKtECY"
   },
   "source": [
    "# ResNet 모델로 Transfer-Learning 하기\n",
    "\n",
    "이전 챕터에서 pytorch 로 resnet 구현과 관련한 내용을 다루었습니다. 이번 노트북에서는 pytorch 로 resnet 모델을 학습하는 방법에 대해 살펴보겠습니다.\n",
    "\n",
    "- 담당자: 권지현 님\n",
    "- 최종수정일: 21-09-29\n",
    "- 본 자료는 가짜연구소 3기 Pytorch guide 크루 활동으로 작성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEGI8ZeKtB-q"
   },
   "source": [
    "## 01 data load\n",
    "\n",
    "본 노트북에서는 `torchvision` 에서 제공하는 데이터 셋을 활용합니다. `torchvision` 에 대한 설명은 링크 를 참조바랍니다.\n",
    "\n",
    "데이터셋을 활용하기 위한 라이브러리를 import 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9X_3vkc0twjm"
   },
   "outputs": [],
   "source": [
    "# torchvision 관련 라이브러리 import\n",
    "\n",
    "from torchvision import utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MyVFwwvtxMv"
   },
   "source": [
    "사용할 데이터 셋은 `STL10` 입니다. `STL10`은 Image Classification 의 벤치마크로 10개의 라벨을 가진 데이터 셋 입니다. `torchvisvion` 에서는 5000개의 train 데이터와 8000개의 test 로 구성되어 있으며, `datasets.STL10` 매소드로 다운받을 수 있습니다.\n",
    "\n",
    "경로를 설정한 후 train, test 데이터를 다운받습니다. 경로는 단순히 root 에 폴더를 생성하여 지정하였습니다.\n",
    "\n",
    "transforms 은 `ToTensor()`로 설정합니다. transforms 에 대한 설명은 링크 를 참조 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "c6ead7bb5c34412786b80a0a427fda74",
      "1de896777889423895dab23a9f53bee9",
      "d971a82ac7764681bbc560d33c560156",
      "e6f28d279c43407bb38530bc1ef53f39",
      "99a91192528749afa2b6c880060fdf64",
      "742b1e06d8a44f6fb036be26c818fadb",
      "8b4c38cdb0984da1828a92133dae5150",
      "0b12b6b96b2d4e62886501cd9b76385e",
      "82e2eff2c6f54f538a5e5556a8672362",
      "bc9b9768f82240f3b56046ce0620811f",
      "674cf273e2854a05a30b02f6ba697130"
     ]
    },
    "id": "a7czYJ6bv2lt",
    "outputId": "68627027-bd78-40f8-c250-b9f6cbecf8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to /test/stl10_binary.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ead7bb5c34412786b80a0a427fda74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2640397119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /test/stl10_binary.tar.gz to /test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.mkdir('./train')\n",
    "os.mkdir('./test')\n",
    "\n",
    "train_dataset = datasets.STL10('/train', split='train', download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.STL10('/test', split='test', download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22aWFTxxzhp"
   },
   "source": [
    "다운받은 이미지에 대해 스케일링 과정이 필요합니다.\n",
    "`transform` 을 활용하여 이미지 크기를 고정하고, `normalization`을 진행합니다.\n",
    "\n",
    "주어진 데이터셋의 이미지는 RGB 3개의 채널로 구성되어 있으므로, 우선 채널 별 mean 값과 std 값을 계산한 후 transform 을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RegO_WFMzqQv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 채널 별 mean 계산\n",
    "def get_mean(dataset):\n",
    "  meanRGB = [np.mean(image.numpy(), axis=(1,2)) for image,_ in dataset]\n",
    "  meanR = np.mean([m[0] for m in meanRGB])\n",
    "  meanG = np.mean([m[1] for m in meanRGB])\n",
    "  meanB = np.mean([m[2] for m in meanRGB])\n",
    "  return [meanR, meanG, meanB]\n",
    "\n",
    "# 채널 별 str 계산\n",
    "def get_std(dataset):\n",
    "  stdRGB = [np.std(image.numpy(), axis=(1,2)) for image,_ in dataset]\n",
    "  stdR = np.mean([s[0] for s in stdRGB])\n",
    "  stdG = np.mean([s[1] for s in stdRGB])\n",
    "  stdB = np.mean([s[2] for s in stdRGB])\n",
    "  return [stdR, stdG, stdB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eq6ZQVfg7Cu9"
   },
   "source": [
    "transforms.Compose 매소드로 trainsform 단계를 묶어서 진행할 수 있습니다. 본 노트북에서는 이미지의 크기를 임의로 128로 고정한 후, 정규화하는 과정만 진행하겠습니다. 보다 다양한 augmentation 방법은 링크 를 참조바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpdeRoQixyeZ"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(get_mean(train_dataset), get_std(train_dataset))])\n",
    "test_transforms = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(get_mean(test_dataset), get_std(test_dataset))])\n",
    "\n",
    "# trainsform 정의\n",
    "train_dataset.transform = train_transforms\n",
    "test_dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKVVrsRj178i"
   },
   "source": [
    "이후 dataloader 를 정의합니다. batch size 는 임의로 128, 64로 설정해두었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jo9Hvgfl17dp"
   },
   "outputs": [],
   "source": [
    "# dataloader 정의\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teVfiHfI2Slo"
   },
   "source": [
    "데이터 사용을 위한 준비가 완료되었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BIVr1SI2fTT"
   },
   "source": [
    "## 02 training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAou45k94kvX"
   },
   "source": [
    "모델 학습을 위해 pretrained 된 resnet 50 모델을 사용하겠습니다.\n",
    "해당 resnet 모델은 사전 학습된 모델로, 이미지 분류 문제를 해결할 수 있도록 규모가 큰 데이터(ImageNet)로 미리 학습된 모델을 의미합니다.\n",
    "\n",
    "torchvision model 에서 구현된 resnet의 구조는 이전 챕터에서 다루었습니다. 관련 내용은 링크 를 참조 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "64f88d4da0814d0587184742691a33f1",
      "96ed0b35f6c4482784b304949b145976",
      "f0b1bd7dad56476291aeaed20e33f259",
      "0d203894b26a44738b2591e53e3c9e7a",
      "09b1806d065947bc99ea68572ea93def",
      "534c27c1ea2e4ecd950ead40b0159406",
      "a089247a37e74194b3b07c88c37795a7",
      "4917d0810bab44689ac3b9ef9504acd1",
      "4ccc933871124cc68af552e110190953",
      "a71db710c20b4443904fcad1c50eeab6",
      "9d7ccc9d82ef4b93a7efe1df2c6ba479"
     ]
    },
    "id": "xWitDppy2SWw",
    "outputId": "0f5c144d-8544-4537-c9f6-46e8ffe23c3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f88d4da0814d0587184742691a33f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 학습 환경 설정\n",
    "model = models.resnet50(pretrained=True).to(device) # true 옵션으로 사전 학습된 모델을 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtyAW4n65Fvo"
   },
   "source": [
    "torchsummary의 summary 매소드로 모델을 요약하여 확인할 수 있습니다. 사용할 데이터 셋은 128*128 크기의 RGB 3개의 chennel로 구성되어 있습니다. 모델의 layer 별 파라미터 개수는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4Iffnww47zW",
    "outputId": "fa848bf3-6796-42af-c074-0eb2d511e141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
      "           Conv2d-13          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
      "             ReLU-15          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-16          [-1, 256, 32, 32]               0\n",
      "           Conv2d-17           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 32, 32]             128\n",
      "             ReLU-19           [-1, 64, 32, 32]               0\n",
      "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      "             ReLU-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "             ReLU-25          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 32, 32]             128\n",
      "             ReLU-29           [-1, 64, 32, 32]               0\n",
      "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      "             ReLU-32           [-1, 64, 32, 32]               0\n",
      "           Conv2d-33          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 32, 32]             512\n",
      "             ReLU-35          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-36          [-1, 256, 32, 32]               0\n",
      "           Conv2d-37          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "             ReLU-39          [-1, 128, 32, 32]               0\n",
      "           Conv2d-40          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 16, 16]             256\n",
      "             ReLU-42          [-1, 128, 16, 16]               0\n",
      "           Conv2d-43          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-45          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-47          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-57          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-58          [-1, 512, 16, 16]               0\n",
      "           Conv2d-59          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 16, 16]             256\n",
      "             ReLU-61          [-1, 128, 16, 16]               0\n",
      "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
      "             ReLU-64          [-1, 128, 16, 16]               0\n",
      "           Conv2d-65          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-67          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
      "           Conv2d-69          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 16, 16]             256\n",
      "             ReLU-71          [-1, 128, 16, 16]               0\n",
      "           Conv2d-72          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
      "             ReLU-74          [-1, 128, 16, 16]               0\n",
      "           Conv2d-75          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-77          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-78          [-1, 512, 16, 16]               0\n",
      "           Conv2d-79          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 16, 16]             512\n",
      "             ReLU-81          [-1, 256, 16, 16]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "           Conv2d-85           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-87           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-89           [-1, 1024, 8, 8]               0\n",
      "       Bottleneck-90           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-99           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-100           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-101            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 8, 8]             512\n",
      "            ReLU-103            [-1, 256, 8, 8]               0\n",
      "          Conv2d-104            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 8, 8]             512\n",
      "            ReLU-106            [-1, 256, 8, 8]               0\n",
      "          Conv2d-107           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-109           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-110           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-111            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 8, 8]             512\n",
      "            ReLU-113            [-1, 256, 8, 8]               0\n",
      "          Conv2d-114            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 8, 8]             512\n",
      "            ReLU-116            [-1, 256, 8, 8]               0\n",
      "          Conv2d-117           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-119           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-120           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-121            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 8, 8]             512\n",
      "            ReLU-123            [-1, 256, 8, 8]               0\n",
      "          Conv2d-124            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 8, 8]             512\n",
      "            ReLU-126            [-1, 256, 8, 8]               0\n",
      "          Conv2d-127           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-129           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-130           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-131            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 8, 8]             512\n",
      "            ReLU-133            [-1, 256, 8, 8]               0\n",
      "          Conv2d-134            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 8, 8]             512\n",
      "            ReLU-136            [-1, 256, 8, 8]               0\n",
      "          Conv2d-137           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-139           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-140           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-141            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-143            [-1, 512, 8, 8]               0\n",
      "          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-146            [-1, 512, 4, 4]               0\n",
      "          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-151           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-155            [-1, 512, 4, 4]               0\n",
      "          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-158            [-1, 512, 4, 4]               0\n",
      "          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-161           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-165            [-1, 512, 4, 4]               0\n",
      "          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-168            [-1, 512, 4, 4]               0\n",
      "          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-171           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 93.59\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 191.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7dEODCd94F5"
   },
   "source": [
    "191 mb 정도의 가벼운 모델 구조를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW4j9JSGCZhd"
   },
   "source": [
    "다음은 모델 학습을 위한 함수를 정의하겠습니다. 가장 간단한 형태의 train 컨테이너를 구성하였습니다.\n",
    "\n",
    "필요한 패키지를 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ru1Z2DUk-KOV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oc3X3xyHKm5I"
   },
   "source": [
    "전이학습을 위해 필요한 파라미터를 정의합니다.\n",
    "`lr` 은 learning rate 로 0.0001 로 설정하였습니다. 많은 epoch 의 학습을 진행할 때에는 스케쥴러를 사용하면 용이하나, 이번 노트북에서는 가장 간단한 형태의 train 컨테이너를 구성하여 다루지 않았습니다.\n",
    "\n",
    "`optimizer` 은 Adam 으로, `loss function` 은 cross entropy 로 정의합니다. loss function 은 학습 목적에 따라 다양하게 구성할 수 있으므로 참고바랍니다.\n",
    "\n",
    "학습 횟수인 `num_epochs` 은 5로 설정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4I6w7hIEEyD7"
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dokU25YL7Om"
   },
   "source": [
    "이때 설정한 파라미터들을 (수정 예정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKOipw809MEX"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_epochs':num_epochs,\n",
    "    'optimizer':optimizer,\n",
    "    'loss_function':loss_function,\n",
    "    'train_dataloader':train_dataloader,\n",
    "    'test_dataloader': test_dataloader,\n",
    "    'device':device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tehbfGEq8d8U"
   },
   "outputs": [],
   "source": [
    "def train(model, params):ㄴ\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    train_dataloader=params[\"train_dataloader\"]\n",
    "    test_dataloader=params[\"test_dataloader\"]\n",
    "    device=params[\"device\"]\n",
    "\n",
    "    for epoch in range(0, num_epochs):\n",
    "      for i, data in enumerate(train_dataloader, 0):\n",
    "        # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 이전 batch에서 계산된 가중치를 초기화\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # forward + back propagation 연산\n",
    "        outputs = model(inputs)\n",
    "        train_loss = loss_function(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "      # test accuracy 계산\n",
    "      total = 0\n",
    "      correct = 0\n",
    "      accuracy = []\n",
    "      for i, data in enumerate(test_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 결과값 연산\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        test_loss = loss_function(outputs, labels).item()\n",
    "        accuracy.append(100 * correct/total)\n",
    "\n",
    "      # 학습 결과 출력\n",
    "      print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epochs, train_loss.item(), test_loss, 100*correct/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2wqhrDfGwRL",
    "outputId": "a58011cd-a3d2-4954-e601-84370c08ab4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5, Train loss: 0.061112, Test loss: 0.425641, Accuracy: 90.45\n",
      "Epoch: 1/5, Train loss: 0.050574, Test loss: 0.275092, Accuracy: 91.41\n",
      "Epoch: 2/5, Train loss: 0.042732, Test loss: 0.229009, Accuracy: 91.83\n",
      "Epoch: 3/5, Train loss: 1.185855, Test loss: 0.299690, Accuracy: 90.94\n",
      "Epoch: 4/5, Train loss: 0.879423, Test loss: 0.334140, Accuracy: 90.74\n"
     ]
    }
   ],
   "source": [
    "train(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acxo_FS9CtUO"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "활용부 초안",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
